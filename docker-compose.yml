services:
  api:
    # API/ASR worker; forwards synthesis requests to the dedicated TTS service.
    build:
      context: .
      dockerfile: backend/Dockerfile.api
    container_name: ai-dub-api
    gpus: all
    environment:
      # Demucs separation and GPU-enabled ASR/MT pipeline knobs
      SEPARATE_BGM: "1"
      USE_GPU: "1"
      MT_DEVICE: "cuda"
      MT_FAST_ONLY: "1"
      MT_NUM_BEAMS: "1"
      MT_MAX_NEW_TOKENS: "96"
      MT_MAX_BATCH_TOKENS: "2048"
      MT_MAX_BATCH_SIZE: "16"
      MT_FP16: "1"
      # Whisper configuration
      WHISPER_MODEL: large-v3
      WHISPER_BATCH_SIZE: "8"
      WHISPER_LANG: ko
      # Remote TTS endpoint; keep local device on CPU to skip redundant model loads
      TTS_URL: "http://tts:9000"
      TTS_DEVICE: "cpu"
      TTS_MODEL: "tts_models/multilingual/multi-dataset/xtts_v2"
      # Shared cache paths (persisted via bind mounts below)
      HF_HOME: /app/cache/hf
      TRANSFORMERS_CACHE: /app/cache/hf
      HUGGINGFACE_HUB_CACHE: /app/cache/hf
      DEMUCS_CACHE: /app/cache/demucs
      TTS_HOME: /app/cache/tts
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    volumes:
      - ./data:/app/data
      - ./data/hf_cache:/app/cache/hf
      - ./data/tts_cache:/app/cache/tts
      - ./data/demucs_cache:/app/cache/demucs
      - ./backend/app:/app/app
    ports:
      - "8000:8000"
    shm_size: "2gb"
    depends_on:
      - tts  # Ensure the synthesizer is ready before accepting API traffic
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload

  tts:
    # XTTS v2 worker; exposes /tts-single for synthesis.
    build:
      context: .
      dockerfile: backend/Dockerfile.tts
    container_name: ai-dub-tts
    gpus: all
    environment:
      # Enable CUDA for XTTS inference
      USE_GPU: "1"
      TTS_DEVICE: "cuda"
      TTS_MODEL: "tts_models/multilingual/multi-dataset/xtts_v2"
      COQUI_TOS_AGREED: "1"
      # Cache paths aligned with host bind mounts
      HF_HOME: /app/cache/hf
      TRANSFORMERS_CACHE: /app/cache/hf
      HUGGINGFACE_HUB_CACHE: /app/cache/hf
      TTS_HOME: /app/cache/tts
      NVIDIA_VISIBLE_DEVICES: "all"
      NVIDIA_DRIVER_CAPABILITIES: "compute,utility"
    volumes:
      - ./data:/app/data
      - ./data/tts_cache:/app/cache/tts
      - ./data/hf_cache:/app/cache/hf
      - ./backend/app:/app/app
    ports:
      - "9000:9000"
    shm_size: "2gb"
    command: uvicorn app.main:app --host 0.0.0.0 --port 9000 --reload
