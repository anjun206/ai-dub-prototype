# AI Dubbing Prototype (Docker)

í•œêµ­ì–´ ì˜ìƒ â†’ ì˜ì–´/ì¼ë³¸ì–´ ë”ë¹™ **í”„ë¡œí† íƒ€ì…**ì…ë‹ˆë‹¤.  
íŒŒì´í”„ë¼ì¸: **FFmpeg ì¶”ì¶œ â†’ faster-whisper(STT) â†’ facebook/m2m100_418M ë²ˆì—­ â†’ Coqui XTTS v2(ë³´ì´ìŠ¤ í´ë¡œë‹ TTS) â†’ íƒ€ì„ìŠ¤íŠ¸ë ˆì¹˜/ì»¨ìº£ â†’ ì˜ìƒì— ì˜¤ë””ì˜¤ êµì²´**

## Docker Layout

```
.
|-- backend/
|   |-- app/                     # FastAPI application (shared source)
|   |-- Dockerfile.api           # API/ASR image definition
|   |-- Dockerfile.tts           # TTS-only image definition
|   |-- requirements.api.txt     # Dependencies for the API container
|   `-- requirements.tts.txt     # Dependencies for the TTS container
`-- docker-compose.yml           # Spins up api + tts services together
```

### Compose Services

| Service | Role | Ports | Notes |
|---------|------|-------|-------|
| `api` | Handles REST requests, runs ASR/translation/mixing, forwards synthesis to TTS over HTTP | `8000` | `TTS_URL` points to the `tts` service; defaults to GPU for Whisper/MT |
| `tts` | Hosts XTTS v2 endpoints (mainly `/tts-single`) | `9000` | Shares the same app code; optimized for GPU synthesis |

### Build & Run

```bash
docker compose build      # Build both images
docker compose up -d      # Launch api + tts containers
```

Interactive docs remain at http://localhost:8000/docs.

## Dependency Breakdown

### backend/requirements.api.txt

- `fastapi`, `uvicorn[standard]`, `python-multipart`: web server core and multipart form uploads.
- `faster-whisper`, `onnxruntime-gpu`: accelerated ASR inference on CUDA.
- `transformers`, `sentencepiece`, `huggingface_hub`: translation model runtime and tokenizer support.
- `soundfile`: WAV IO for intermediate audio assets.
- `sacremoses`, `cutlet`, `fugashi`, `unidic-lite`: Japanese tokenization/romanization helpers used in translation stages.
- `requests`: API container calls the remote TTS worker over HTTP.
- `webrtcvad`: Voice-activity detection fallback for silence trimming.
- `torchcodec`: referenced utilities for audio manipulation in the pipeline.

### backend/requirements.tts.txt

- `fastapi`, `uvicorn[standard]`, `python-multipart`: same FastAPI surface hosting `/tts-single`.
- `TTS`: Coqui XTTS v2 synthesis library.
- `soundfile`: read/write support for the generated waveforms.
- `requests`: keeps parity with the API environment when issuing auxiliary HTTP calls.

## docker-compose Overview

`docker-compose.yml` builds both images from the repository root, mounts the `backend/app` directory for live code reloads, and shares host caches (`./data/hf_cache`, `./data/tts_cache`, `./data/demucs_cache`) so model downloads persist between runs. The `api` service depends on `tts`, ensuring the synthesizer is ready before accepting external traffic.

Key environment variables:

- `TTS_URL` points the API container at the TTS worker (`http://tts:9000`) so synthesis happens remotely.
- `USE_GPU`, `MT_DEVICE`, `TTS_DEVICE`, `NVIDIA_VISIBLE_DEVICES` toggle CUDA usage; set explicit device IDs to split workloads across GPUs.
- `HF_HOME`, `TRANSFORMERS_CACHE`, `TTS_HOME`, `DEMUCS_CACHE` align cache paths with host bind mounts to avoid re-downloading weights.
- `MT_*` knobs control translation beam search and batching to balance speed and accuracy.

## API Quick Start

## ğŸ§ª ì‚¬ìš© ë°©ë²•

localhost:8000/docsì— ë“¤ì–´ê°€ì„œ swaggerë¥¼ í†µí•´ ì‚¬ìš©ê°€ëŠ¥

- POST: asr<br>
mp4 íŒŒì¼ ì—…ë¡œë“œì‹œ ë°°ê²½ìŒ ì¶”ì¶œ, sttí›„ meta.json ìƒì„±
meta.jsonì— í´ë” id ê¸°ë¡ë¨

- POST: translate<br>
meta.jsonì˜ ì›ë¬¸ ë²ˆì—­

PATCH ë¶™ì€ ì• ë“¤ì€ ë³´í†µ ìˆ˜ì •ì¸ë° ê·¸ëƒ¥ meta.jsonì—ì„œ ì§ì ‘ ìˆ˜ì •í•˜ëŠ” ê±° ê¶Œì¥

- POST: tts-probe<br>
tts ê°„ë‹¨íˆ ëŒë ¤ ì›ë¬¸ê³¼ ë³€ì—­ë³¸ ë°œí™” ì‹œê°„ ë¹„êµ
(ì—¬ëŸ¬ë²ˆ ê°€ëŠ¥)

- POST: tts-finalize<br>
ìµœì¢… ttsë¡œ ì–´ê¸‹ë‚˜ëŠ” ë°œí™”ì‹œê°„ì€ ê³µë°± ì‹œê°„ í™œìš©, ìŒì„± ë°°ì†/ê°ì†ìœ¼ë¡œ ì‹±í¬ ë§ì¶¤

- POST: tts-single<br>
ê°„ë‹¨í•˜ê²Œ í…ìŠ¤íŠ¸ ë„£ê³  ttsë§Œ ì‚¬ìš©ê°€ëŠ¥

- POST: mux<br>
tts-finalize ì´í›„ ì˜ìƒê³¼ ì˜¤ë””ì˜¤ í•©ì„±
 -> `output`

- POST: merge<br>
asr ì´í›„ ì„¸ê·¸ë¨¼íŠ¸ ë¸”ë¡ ë³‘í•© ê°€ëŠ¥ (0ë²ˆë¶€í„° ì‹œì‘)

- POST: voice-sample<br>
ì—…ë¡œë“œí•œ íŒŒì¼ì—ì„œ ë°°ê²½ìŒ ì œê±°í•´ ìŒì„±ë§Œ ì¶”ì¶œ .wavë¡œ ë§Œë“¦

## Voice Sample Utility

- Call `POST /voice-sample` with any media file to generate a six-second reference clip stored at `./data/<job_id>/voice_sample_24k.wav`.
- Useful for creating voice references that can be reused with `/dub`, `/tts-probe`, or `/tts-single`.

```powershell
Invoke-WebRequest -Uri http://localhost:8000/voice-sample -Method Post -Form @{
  file = Get-Item .\sample.mp4
} -OutFile voice_sample.wav
```

## Storage Layout

- `./data`: per-job workspace (inputs, intermediates, final renders) shared across containers.
- `./data/hf_cache`, `./data/tts_cache`, `./data/demucs_cache`: model caches for Hugging Face, Coqui XTTS, and Demucs separation (safe to clear when reclaiming disk).
